\section{引言}

6D物体位姿估计是计算机视觉领域的核心挑战之一，在增强现实\cite{10450983}和机器人技术\cite{9727342}中具有重要应用价值。尤其在机器人操作任务中，准确获取物体的三维位置与方向信息，可为抓取规划和运动控制提供关键支撑。本章重点研究基于单目RGB图像的物体位姿估计方法。当前主流方法\cite{su2022zebrapose, symnet}通常通过神经网络生成可见掩码（物体可见区域）和完整掩码（无遮挡情况下的物体区域），并结合其他特征建立空间对应关系以推导最终位姿。

位姿优化指的是在有一个精度较低的初始位姿的条件下，通过某一方法提升该初始位姿的精度，输出更准确的位姿估计结果。这种方法往往依赖渲染，例如，CIR\cite{lipson2022coupled}通过一种新颖的可微分求解器层，在渲染和比较策略下迭代地同时优化姿态和密集对应关系。PFA\cite{hu2022perspective}提出了一种非迭代的姿态优化策略，通过预测渲染图像和真实图像之间的密集对应场来实现。迭代最近点算法（ICP）通常作为一种优化策略，与仅使用RGB的初始姿态估计相结合，利用深度信息将估计的物体点云与图像对齐。目前，依赖于像PFA和CIR这样的网络实现位姿精度的进一步提升是一种主流方法。然而，这些方法通常需要额外训练迭代优化网络，而本章的目标是实现一种无需额外训练的用于RGB输入条件下的通用优化方法。基于轮廓的对齐方式被提出，这是因为轮廓信息在位姿估计任务中通常未被显式利用，而轮廓对齐往往作为评价指标的一部分。

基于轮廓的对齐是一种广泛应用于6D物体跟踪的方法\cite{wuest2005adaptive}，这种方法不依赖物体模型中的颜色和纹理。RGBT\cite{RGBT}和SRT3D\cite{SRT3D}是基于区域的6D物体跟踪的高效方法。这些方法仅依赖单目RGB相机，通过基于直方图的建模来建立轮廓位置概率。本章从上述方法中汲取灵感，在位姿估计的背景下提出来基于轮廓对齐的位姿估计优化方法。与上述方法不同，该方法通过利用掩码进行轮廓提取，而不直接使用直方图搜寻物体的轮廓。

相比之下，提出的方法，如\autoref{fig:ca_teaser}所示，无需训练新网络即可实现姿态优化。此外，该优化方法可无缝集成到现有的单目6D姿态估计方法中，从而更精确地估计物体的位姿。

\begin{figure}[ht]
  \centering
  \begin{overpic}[width=0.85\textwidth]{figure/ca/teaser.jpg}
      \put (1,16) {RGB图像}
      \put (23,15) {\rotatebox{270}{CNN}}
      \put (23,45) {\rotatebox{270}{CNN}}
      \put (61,2) {$CoI$}
      \put (63,47) {初始位姿}
      \put (66,33) {\rotatebox{270}{迭代优化}}
      \put (85,11) {位姿输出}
  \end{overpic}
  \caption{方法示意图}
  \label{fig:ca_teaser}
\end{figure}

该方法假设学习到的掩码的准确性优于初始位姿估计的准确性。这个假设一般都能够成立，因为学习掩码本身就是网络的中间过程，其精度能够直接影响位姿估计精度。实验结果也能够支持这一观点。在物体轮廓与渲染轮廓不对齐的情况下，这种差异表明当前的位姿估计不够准确。在这种情况下，可以采用一个优化过程来优化估计的位姿。

当深度信息可用时，像ICP或基于网络的优化方法\cite{lipson2022coupled}可以显著提升结果。然而，在没有深度图的情况下，常见的优化方法是训练一个依赖于渲染和比较机制的网络，例如DeepIM\cite{li2018deepim}。本章从初始位姿和感兴趣轮廓（CoI）开始，优化过程采用轮廓对齐，而不依赖于神经网络。

总之，该工作做出了以下关键贡献：

\begin{enumerate}
\item 引入了一种基于轮廓对齐的优化方法，作为网络优化方法的替代方案。该方法能够作为组件用于现有基于RGB的位姿估计方法中。
\item 证明了即使是密集特征得到的位姿估计结果，显式使用边缘信息仍然能够进一步提升精度。
\item 这种轮廓的优化方法可以作为位姿估计结果的评价指标和自我测评方案，有效减少网络输出的假正例。
\item 在YCB-V\cite{ycbv}和IC-BIN\cite{icbin}等基准数据集上进行了实验，以展示提出方法的有效性和效率。
\end{enumerate}
