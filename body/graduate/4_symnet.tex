\chapter{针对对称性歧义的RGB物体位姿估计方法}

本章立足于解决物体位姿估计中的对称性问题，并提出来一种基于RGB相机的端到端物体位姿估计方法。首先，详细剖析位姿估计中的对称性问题，并且指出了其在建立对应关系中存在的对称性歧义。为了解决这个问题，提出一对多对应关系的概念，并基于此提出一种对称感知的表面编码（SymCode），它基于一对多的对应关系对物体表面顶点进行编码，消除了一对一对应关系的歧义问题。最后，把一对多对应关系作为辅助约束，直接回归6D位姿参数，实现端到端的位姿估计。该方法在主要是对称物体的T-LESS和IC-BIN基准测试中展示了更快的运行时间和可比的准确性。代码可在 \href{https://github.com/lyltc1/SymNet}{https://github.com/lyltc1/SymNet} 获取。

\inputbody{4_1_symnet_introduction.tex}
\inputbody{4_2_symnet_method.tex}
\inputbody{4_3_symnet_experiment.tex}

\section{本章小结}
本章提出了一种从单张RGB图像中估计物体6D位姿的方法，这一任务在处理对称物体时更具挑战性。传统方法通常在图像像素与3D物体表面观测点之间建立一对一的对应关系，但这种做法在对称物体上引入了歧义性。为了解决这一问题，提出了SymCode，一种对称感知的表面编码方法。SymCode基于一对多的对应关系对物体表面顶点进行编码，有效消除了单一对应关系带来的歧义问题。此外，还引入了SymNet，一个快速的端到端深度学习网络。SymNet能够直接回归6D位姿参数，而无需通过PnP问题进行求解，从而显著提升了位姿估计的效率与准确性。