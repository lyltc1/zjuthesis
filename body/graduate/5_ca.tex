\chapter{基于边缘优化的RGB物体位姿估计优化方法}

本章节提出了一种基于边缘优化的物体位姿估计优化技术。传统的物体位姿估计方法通常能够生成可见掩码和完整掩码，而我们的方法进一步从中提取感兴趣轮廓（Contour of Interest，CoI），并利用这些轮廓与初始位姿渲染的轮廓进行对齐优化。我们的核心思想是，轮廓对齐不仅可以作为准确估计位姿的关键标准，还能够为位姿优化过程提供有效的梯度支持。值得注意的是，与基于完整渲染图像的方法不同，我们的方法仅依赖于分割渲染结果，无需额外训练优化网络。这一特点显著降低了优化过程的计算复杂度，同时增强了方法的灵活性，使其能够与其他技术无缝结合。为了验证所提方法的有效性，我们在YCB-V和IC-BIN基准数据集上进行了全面的实验评估，实验结果表明了该方法的优越性和鲁棒性。实验结果也说明了当前的深度学习方法还能够通过手工设计一些特殊的优化因子实现精度的提升。相关代码已开源，详见 \href{https://github.com/lyltc1/ContourAlignment}{https://github.com/lyltc1/ContourAlignment}。

\inputbody{5_1_ca_introduction.tex}
\inputbody{5_2_ca_method.tex}
\inputbody{5_3_ca_experiment.tex}

\section{本章小结}
本章提出一种基于轮廓对齐的物体位姿优化方法。该方法的核心创新在于通过可见掩码与完整掩码提取感兴趣轮廓，并基于此与初始位姿渲染轮廓的几何一致性建立优化目标。具体而言，通过将实际观测轮廓与当前位姿的渲染轮廓进行对齐，构建轮廓匹配误差函数，利用其梯度迭代优化位姿参数。与传统依赖图像渲染与像素级比较的方法不同，本方法仅需渲染物体分割轮廓，无需引入额外的优化网络训练过程，从而显著降低了计算复杂度。这种轻量化设计使位姿优化过程摆脱了对高维特征匹配的依赖，在保证精度的同时实现准确率的提升。