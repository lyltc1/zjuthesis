本章介绍一种从单幅RGB-D图像中进行6自由度物体位姿估计的实例级物体位姿估计方法。当前同类研究中的领先方法依赖于基于渲染的精调流程，在实时性上有一定的瓶颈。基于渲染的精调流程需要渲染器渲染出当前估计姿态所对应的图像，渲染过程需要耗费较多的资源。为了规避渲染耗时的局限性，我们提出了基于层次化表面编码和对应关系剪枝的HiPose架构，该方法通过层次化的二进制表面编码以粗到精的方式建立观测点到模型表面区域的对应关系。与之前的稠密对应方法不同，我们通过采用点到表面匹配来估计对应表面，并迭代性地收缩表面，直到其转变为对应点，同时逐渐去除离群点。在公共基准数据集 LM-O、YCB-V 和 T-LESS 上进行的大量实验显示，我们的方法在不依赖精调流程的方案中表现最优，甚至能与那些相对耗时的基于渲染的方法相抗衡。尤为重要的是，我们的方法计算效率极高，这使其能够在对精度要求苛刻的实时关键应用场景中发挥作用。代码链接见 \url{https://github.com/lyltc1/HiPose}。

\section{引言}
在缺乏纹理和严重遮挡的场景中，6DoF位姿估计仍具有挑战。近期的一些仅基于RGB的研究~\cite{zakharov2019dpod,park2019pix2pose,su2022zebrapose}在处理遮挡方面表现良好，但因单目图像存在深度不确定性而造成了精度下降。而一些基于RGB-D的方法\cite{wang2019densefusion, he2020pvn3d,he2021ffb6d,zhou2023deep}提出了新颖的特征融合网络，以更好地利用RGB和深度信息，但在公共基准如BOP\cite{Sundermeyer2023BOPC2}上的表现仍落后。相较之下，目前大多数最先进的方法通常先利用RGB图像估计位姿，然后利用深度信息进行迭代的位姿精调流程~\cite{Rusinkiewicz2001EfficientVO,lipson2022coupled}。与之不同的是，我们提出的HiPose直接利用RGB-D图像进行位姿估计能够提供更精确、更可靠的物体位姿估计。

在本章中，我们旨在充分利用RGB-D图像中的详细信息，以估计准确的物体位姿，而无需任何耗时的精细化调整步骤。通过使用RGB-D输入，我们得益于诸如点到表面距离等额外信息。受到最近工作ZebraPose~\cite{su2022zebrapose}的启发，我们引入了HiPose，这是一个有效预测输入深度图和物体模型之间密集3D-3D对应的网络。与ZebraPose~\cite{su2022zebrapose}不同，我们处理编码的方式更好地利用其粗到精的性质，通过迭代去除离群点。

我们提出了一种新颖且更为稳定的层次化对应剪枝方法，而不是在常见的RANSAC框架下使用预测的对应关系来解决位姿问题，如与Kabsch算法~\cite{umeyama1991least}常结合的方法那样。具体而言，层次化二进制编码输出中的粗略预测更不容易出错，提供了一个稳健的初始位姿。这一粗略位姿有助于基于点到表面距离识别和去除离群匹配。随后，我们在每次迭代中应用更精细的预测，逐步完善我们的位姿预测，并在更细的层面上去除离群点，以提高精度。

总体而言，我们的贡献可以总结如下：
\begin{itemize}
\item 我们提出了一种充分利用RGB-D数据的物体位姿估计方法，专注于通过层次化二进制表面编码进行3D-3D对应匹配。
\item 我们引入了一种基于层次化对应剪枝的RANSAC-free位姿估计方法，通过粗到精的子表面去除离群点。
\item 在LM-O、YCB-V和T-LESS数据集上的大量实验表明我们方法的有效性。我们在没有任何额外精细化的情况下实现了最先进的结果，使我们的方案明显快于其他方法，适合实时应用。
\end{itemize}
